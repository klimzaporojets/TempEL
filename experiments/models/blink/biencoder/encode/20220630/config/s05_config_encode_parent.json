{
  "description": "encodes tokenized wikipedia file with fine-tuned(trained) biencoder (see config/models/blink/biencoder/train)",
  "base_experiment_path": "experiments/",
  "input_file": "snapshot_extraction/snap_20220515/output/wikipedia_evolution_content.jsonl",
  "produce_encoded_jsonl": false,
  "initial_capacity": 1000000,
  "increment_capacity": 100000000,
  "str_buffer_size": 10000,
  "_str_buffer_size": "in megabytes",
  "str_buffer_nr_files": 100000,
  "_str_buffer_nr_files": "in nr of processed entities",
  "str_buffer_nr_files_in_gatherer": 500000,
  "_str_buffer_nr_files_in_gatherer": "the ones used to build tensors and dictionaries of labels to wikidata_qids and the other way around",
  "nr_threads_per_gpu": 3,
  "model": {
    "encode_batch_size": 8,
    "max_cand_length": 128,
    "use_candidate_title": true,
    "bert_model": "bert-large-uncased",
    "lowercase": true,
    "bert_cache_dir": "data/caches/cache_bert/",
    "no_cuda": false,
    "out_dim": 1,
    "pull_from_layer": -1,
    "add_linear": false
  },
  "time_cut_list": [
    "2013-01-01T00:00:00Z",
    "2014-01-01T00:00:00Z",
    "2015-01-01T00:00:00Z",
    "2016-01-01T00:00:00Z",
    "2017-01-01T00:00:00Z",
    "2018-01-01T00:00:00Z",
    "2019-01-01T00:00:00Z",
    "2020-01-01T00:00:00Z",
    "2021-01-01T00:00:00Z",
    "2022-01-01T00:00:00Z"
  ]
}